{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Project: Predict Wine Quality with Regularization\n",
    "\n",
    "\n",
    "\n",
    "The data is from the Wine Quality Dataset in the UCI Machine Learning Repository. We’re looking at the red wine data in particular and while the original dataset has a 1-10 rating for each wine, we’ve made it a classification problem with a wine quality of good (>5 rating) or bad (<=5 rating). The goals of this project is to model wine quality based on physicochemical tests. In order to get there I will perform task including:\n",
    "\n",
    "\n",
    "* implement different logistic regression classifiers\n",
    "* find the best ridge-regularized classifier using hyperparameter tuning\n",
    "* implement a tuned lasso-regularized feature selection method\n",
    "\n",
    "Let's explore these options by looking at the data we have available to us. First let's answer few questions:\n",
    "\n",
    "* What the total number of records in the dataset?\n",
    "* What are the columns, or features, of the dataset?\n",
    "* What is the test result of the first wine in the dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
      "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
      "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n",
      "None\n",
      "There are 1599, records and 12 features\n",
      "Taste of the first wine in data set in 1-10 scale:  5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.read_csv('wine_quality.csv', delimiter=';')\n",
    "print(data.columns)\n",
    "print(data.info())\n",
    "print(f'There are {data.shape[0]}, records and {data.shape[1]} features')\n",
    "print(f'Taste of the first wine in data set in 1-10 scale: ', data.iloc[0,-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['quality']\n",
    "features = data.drop(columns = ['quality'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin modeling, let’s scale our data using `StandardScaler()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standard_scaler_fit = StandardScaler().fit(features)\n",
    "X = standard_scaler_fit.transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform an 80:20 train-test split on the data. Set the random_state to 7 for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a classifier, `clf_no_reg`, a logistic regression model without regularization and fit it to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_no_reg = LogisticRegression()\n",
    "clf_no_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I am going to plot the `coefficients` obtained from fitting the Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (66) does not match length of index (11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\olafk\\Desktop\\Projects\\Wine-Quality\\winequality.ipynb Komórka 11\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/olafk/Desktop/Projects/Wine-Quality/winequality.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m predictors \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/olafk/Desktop/Projects/Wine-Quality/winequality.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m coefficients \u001b[39m=\u001b[39m clf_no_reg\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mravel()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/olafk/Desktop/Projects/Wine-Quality/winequality.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m coef \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mSeries(coefficients, predictors)\u001b[39m.\u001b[39msort_values()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/olafk/Desktop/Projects/Wine-Quality/winequality.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m coef\u001b[39m.\u001b[39mplot(kind\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbar\u001b[39m\u001b[39m'\u001b[39m, title \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mCoefficients (no regularization)\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/olafk/Desktop/Projects/Wine-Quality/winequality.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mtight_layout()\n",
      "File \u001b[1;32md:\\Programing\\Anaconda\\lib\\site-packages\\pandas\\core\\series.py:442\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    440\u001b[0m     index \u001b[39m=\u001b[39m default_index(\u001b[39mlen\u001b[39m(data))\n\u001b[0;32m    441\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n\u001b[1;32m--> 442\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(data, index)\n\u001b[0;32m    444\u001b[0m \u001b[39m# create/copy the manager\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, (SingleBlockManager, SingleArrayManager)):\n",
      "File \u001b[1;32md:\\Programing\\Anaconda\\lib\\site-packages\\pandas\\core\\common.py:557\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[1;32m--> 557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    558\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    560\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    561\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    562\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (66) does not match length of index (11)"
     ]
    }
   ],
   "source": [
    "predictors = features.columns\n",
    "coefficients = clf_no_reg.coef_.ravel()\n",
    "print(coefficients)\n",
    "\n",
    "coef.plot(kind='bar', title = 'Coefficients (no regularization)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\olafk\\Desktop\\Projects\\Wine-Quality\\winequality.ipynb Komórka 12\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/olafk/Desktop/Projects/Wine-Quality/winequality.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y_pred_test \u001b[39m=\u001b[39m clf_no_reg\u001b[39m.\u001b[39mpredict(x_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/olafk/Desktop/Projects/Wine-Quality/winequality.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y_pred_train \u001b[39m=\u001b[39m clf_no_reg\u001b[39m.\u001b[39mpredict(x_train)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/olafk/Desktop/Projects/Wine-Quality/winequality.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTraining Score\u001b[39m\u001b[39m'\u001b[39m, f1_score(y_train, y_pred_train))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/olafk/Desktop/Projects/Wine-Quality/winequality.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTesting Score\u001b[39m\u001b[39m'\u001b[39m, f1_score(y_test, y_pred_test))\n",
      "File \u001b[1;32md:\\Programing\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1123\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf1_score\u001b[39m(\n\u001b[0;32m    993\u001b[0m     y_true,\n\u001b[0;32m    994\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1000\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1001\u001b[0m ):\n\u001b[0;32m   1002\u001b[0m     \u001b[39m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m \n\u001b[0;32m   1004\u001b[0m \u001b[39m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[39m    modified with ``zero_division``.\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m     \u001b[39mreturn\u001b[39;00m fbeta_score(\n\u001b[0;32m   1124\u001b[0m         y_true,\n\u001b[0;32m   1125\u001b[0m         y_pred,\n\u001b[0;32m   1126\u001b[0m         beta\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   1127\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1128\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1129\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1130\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1131\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1132\u001b[0m     )\n",
      "File \u001b[1;32md:\\Programing\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1261\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfbeta_score\u001b[39m(\n\u001b[0;32m   1136\u001b[0m     y_true,\n\u001b[0;32m   1137\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1145\u001b[0m ):\n\u001b[0;32m   1146\u001b[0m     \u001b[39m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m \n\u001b[0;32m   1148\u001b[0m \u001b[39m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[39m    array([0.71..., 0.        , 0.        ])\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1261\u001b[0m     _, _, f, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m   1262\u001b[0m         y_true,\n\u001b[0;32m   1263\u001b[0m         y_pred,\n\u001b[0;32m   1264\u001b[0m         beta\u001b[39m=\u001b[39;49mbeta,\n\u001b[0;32m   1265\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1266\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1267\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1268\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mf-score\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[0;32m   1269\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1270\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1271\u001b[0m     )\n\u001b[0;32m   1272\u001b[0m     \u001b[39mreturn\u001b[39;00m f\n",
      "File \u001b[1;32md:\\Programing\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1544\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1542\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1543\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1544\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m   1546\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1547\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32md:\\Programing\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1365\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1363\u001b[0m         \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1364\u001b[0m             average_options\u001b[39m.\u001b[39mremove(\u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1365\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1366\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTarget is \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m but average=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. Please \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1367\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mchoose another average setting, one of \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (y_type, average_options)\n\u001b[0;32m   1368\u001b[0m         )\n\u001b[0;32m   1369\u001b[0m \u001b[39melif\u001b[39;00m pos_label \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39m1\u001b[39m):\n\u001b[0;32m   1370\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1371\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNote that pos_label (set to \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) is ignored when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maverage != \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m (got \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m). You may use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1375\u001b[0m         \u001b[39mUserWarning\u001b[39;00m,\n\u001b[0;32m   1376\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_pred_test = clf_no_reg.predict(x_test)\n",
    "y_pred_train = clf_no_reg.predict(x_train)\n",
    "print('Training Score', f1_score(y_train, y_pred_train))\n",
    "print('Testing Score', f1_score(y_test, y_pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e925636a0b7c6026e16ceba626bc40dea2d843d871da5cfe06b4755fd84dac6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
